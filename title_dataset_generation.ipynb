{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies (optional) üîß\n",
    "\n",
    "This cell lists optional pip install commands to install required packages for this notebook. Uncomment and run if you need to install `vllm`, `openai`, or `tqdm`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install vllm openai tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start vLLM server (overview) üöÄ\n",
    "\n",
    "This section contains code to start a vLLM OpenAI-compatible server locally. The server is launched with model-specific arguments and the script waits until the `/v1/models` endpoint responds successfully. Adjust GPU/memory flags as needed for your environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start vLLM server (start & wait) ‚öôÔ∏è\n",
    "\n",
    "Starts the server in the background using `subprocess.Popen` and polls the model endpoint until it returns HTTP 200. The code also contains a commented-out option for alternate start parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting vLLM server...\n",
      "Waiting... (0s)\n",
      "Waiting... (10s)\n",
      "Waiting... (20s)\n",
      "Waiting... (30s)\n",
      "‚úÖ vLLM server is ready!\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# Kill any existing vLLM process\n",
    "!pkill -f vllm.entrypoints.openai.api_server\n",
    "\n",
    "# Start vLLM server in background\n",
    "# vllm_process = subprocess.Popen([\n",
    "#     \"python\", \"-m\", \"vllm.entrypoints.openai.api_server\",\n",
    "#     \"--model\", \"Qwen/Qwen2.5-7B-Instruct\",\n",
    "#     \"--host\", \"0.0.0.0\",\n",
    "#     \"--port\", \"8000\",\n",
    "#     \"--gpu-memory-utilization\", \"0.9\",\n",
    "#     \"--max-model-len\", \"4096\"\n",
    "# ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "vllm_process = subprocess.Popen([\n",
    "    \"python\", \"-m\", \"vllm.entrypoints.openai.api_server\",\n",
    "    \"--model\", \"Qwen/Qwen2.5-7B-Instruct\",\n",
    "    \"--host\", \"0.0.0.0\",\n",
    "    \"--port\", \"8000\",\n",
    "    \"--gpu-memory-utilization\", \"0.85\",  # Lower from 0.9\n",
    "    \"--max-model-len\", \"2048\",  # Lower from 4096\n",
    "    \"--disable-log-requests\",  # Reduce overhead\n",
    "    \"--max-num-seqs\", \"8\",  # Handle more concurrent requests\n",
    "    \"--swap-space\", \"4\"  # Add swap space\n",
    "], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "# Wait for server to be ready\n",
    "print(\"Starting vLLM server...\")\n",
    "for i in range(60):\n",
    "    try:\n",
    "        response = requests.get(\"http://localhost:8000/v1/models\")\n",
    "        if response.status_code == 200:\n",
    "            print(\"‚úÖ vLLM server is ready!\")\n",
    "            break\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(2)\n",
    "    if i % 5 == 0:\n",
    "        print(f\"Waiting... ({i*2}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check vLLM server health ‚úÖ\n",
    "\n",
    "A quick health check that queries `http://localhost:8000/v1/models` to verify the server is responsive. Useful to run after starting or restarting the server.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/v1/models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Install pandas üßæ\n",
    "\n",
    "Commented pip line to install `pandas` if the environment does not already have it. Uncomment to run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset CSV into pandas üì•\n",
    "\n",
    "Loads `studio_results_20260104_1052.csv` into a DataFrame for subsequent processing. Inspect the head to confirm successful load.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Growth Analyst</td>\n",
       "      <td>Statistical analysis, SQL, Scripting (Ruby, Py...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Brand Designer (Contract)</td>\n",
       "      <td>Graphic Design, digital design, print design, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accounts Support Specialist</td>\n",
       "      <td>problem solving, customer support, writing, gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Site Reliability Engineer</td>\n",
       "      <td>Windows Server, Microsoft Azure, PowerShell, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Site Reliability Engineer</td>\n",
       "      <td>Windows Server, Microsoft Azure, PowerShell, S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title  \\\n",
       "0                    Growth Analyst   \n",
       "1  Senior Brand Designer (Contract)   \n",
       "2       Accounts Support Specialist   \n",
       "3         Site Reliability Engineer   \n",
       "4         Site Reliability Engineer   \n",
       "\n",
       "                                              skills  \n",
       "0  Statistical analysis, SQL, Scripting (Ruby, Py...  \n",
       "1  Graphic Design, digital design, print design, ...  \n",
       "2  problem solving, customer support, writing, gr...  \n",
       "3  Windows Server, Microsoft Azure, PowerShell, S...  \n",
       "4  Windows Server, Microsoft Azure, PowerShell, S...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"studio_results_20260104_1052.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create list of anchor titles üìù\n",
    "\n",
    "Extract the `title` column as a Python list (`skills_list`) which will be used as input anchors for triplet generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills_list = df[\"title\"].tolist()\n",
    "len(skills_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup vLLM-compatible OpenAI client üîå\n",
    "\n",
    "Import required modules and create an `OpenAI` client pointing to the local vLLM server. `api_key` is set to a dummy value because vLLM is OpenAI-compatible (no real key needed for local server).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Optional, Dict, List\n",
    "import time\n",
    "\n",
    "\n",
    "# vLLM OpenAI-compatible client\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"dummy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt template for triplet generation ‚úçÔ∏è\n",
    "\n",
    "Defines `build_prompt(anchor)` which instructs the model to output a JSON object with `positive` and `negative` fields given an anchor sentence. The prompt enforces strict JSON output (no explanations).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(anchor: str) -> str:\n",
    "    return f\"\"\"\n",
    "You are a dataset generator for semantic similarity training.\n",
    "\n",
    "Given an ANCHOR sentence, generate:\n",
    "1. POSITIVE: A sentence with the SAME meaning as the anchor.\n",
    "2. NEGATIVE: A sentence from the SAME DOMAIN but DIFFERENT meaning.\n",
    "\n",
    "Rules:\n",
    "- Do NOT copy anchor text exactly\n",
    "- Keep language and tone consistent\n",
    "- Do NOT explain anything\n",
    "- Output STRICT JSON only\n",
    "\n",
    "JSON format:\n",
    "{{\n",
    "  \"positive\": \"...\",\n",
    "  \"negative\": \"...\"\n",
    "}}\n",
    "\n",
    "ANCHOR:\n",
    "{anchor}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a single triplet with retries üîÅ\n",
    "\n",
    "`generate_triplet(anchor)` calls the model, strips code fences, parses JSON, and retries on errors. Returns a dict with `anchor`, `positive`, and `negative` or `None` on failure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Functions loaded!\n"
     ]
    }
   ],
   "source": [
    "def generate_triplet(anchor: str, max_retries: int = 2) -> Optional[Dict]:\n",
    "    \"\"\"Generate a single triplet with retry logic.\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"Qwen/Qwen2.5-7B-Instruct\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You generate high-quality contrastive training data in JSON format.\"},\n",
    "                    {\"role\": \"user\", \"content\": build_prompt(anchor)}\n",
    "                ],\n",
    "                temperature=0.7,\n",
    "                max_tokens=256,\n",
    "                timeout=30\n",
    "            )\n",
    "\n",
    "            content = response.choices[0].message.content.strip()\n",
    "            content = content.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "            parsed = json.loads(content)\n",
    "            \n",
    "            if \"positive\" not in parsed or \"negative\" not in parsed:\n",
    "                continue\n",
    "                \n",
    "            return {\n",
    "                \"anchor\": anchor,\n",
    "                \"positive\": parsed[\"positive\"],\n",
    "                \"negative\": parsed[\"negative\"]\n",
    "            }\n",
    "            \n",
    "        except json.JSONDecodeError:\n",
    "            if attempt == max_retries - 1:\n",
    "                print(f\"‚ùå JSON parse failed: {anchor[:50]}...\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                print(f\"‚ùå Error: {e}\")\n",
    "            time.sleep(0.1)\n",
    "            continue\n",
    "    \n",
    "    return None\n",
    "\n",
    "print(\"‚úÖ Functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test single generation ‚úÖ\n",
    "\n",
    "Quick test that runs `generate_triplet` on a sample anchor and prints the result. Use this to validate the vLLM server and parsing logic before generating the full dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a single test and inspect output üîç\n",
    "\n",
    "Execute a single example and print the returned JSON to ensure `positive` and `negative` fields are present and well-formed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Test successful!\n",
      "{\n",
      "  \"anchor\": \"Python programming for data analysis\",\n",
      "  \"positive\": \"Learning Python to manipulate datasets\",\n",
      "  \"negative\": \"Building a website using Python frameworks\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test with one example\n",
    "test_anchor = \"Python programming for data analysis\"\n",
    "test_result = generate_triplet(test_anchor)\n",
    "\n",
    "if test_result:\n",
    "    print(\"‚úÖ Test successful!\")\n",
    "    print(json.dumps(test_result, indent=2))\n",
    "else:\n",
    "    print(\"‚ùå Test failed - check vLLM server\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook UI dependencies (optional) üß©\n",
    "\n",
    "Commented instruction to upgrade `notebook` and `ipywidgets`. Useful when using widgets or interactive progress bars in some environments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade notebook ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress bar example (commented) ‚è≥\n",
    "\n",
    "A minimal example showing how to use `tqdm.notebook.tqdm` for progress feedback when generating triplets. Kept commented for reference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "# for i in tqdm(range(10),  desc=\"Generating Triplets\"):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize dataset containers üìö\n",
    "\n",
    "Create `dataset` for successful triplets and `failed_anchors` to record anchors that could not be generated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "failed_anchors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset initialization and bookkeeping üßæ\n",
    "\n",
    "`dataset` will hold valid triplets and `failed_anchors` will collect any anchors that fail generation after retries. These lists are used during long-running generation loops and checkpointing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_dataset_parallel(\n",
    "#     anchors: List[str], \n",
    "#     max_workers: int = 8,  # Lower default\n",
    "#     timeout: int = 60  # Per request timeout\n",
    "# ) -> List[Dict]:\n",
    "#     \"\"\"Generate dataset with parallel processing.\"\"\"\n",
    "#     dataset = []\n",
    "#     failed_anchors = []\n",
    "    \n",
    "#     with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "#         future_to_anchor = {\n",
    "#             executor.submit(generate_triplet, anchor): anchor \n",
    "#             for anchor in anchors\n",
    "#         }\n",
    "        \n",
    "#         for future in tqdm(\n",
    "#             as_completed(future_to_anchor, timeout=timeout), \n",
    "#             total=len(anchors),\n",
    "#             desc=\"Generating Triplets\"\n",
    "#         ):\n",
    "#             try:\n",
    "#                 anchor = future_to_anchor[future]\n",
    "#                 result = future.result(timeout=timeout)\n",
    "                \n",
    "#                 if result:\n",
    "#                     dataset.append(result)\n",
    "#                 else:\n",
    "#                     failed_anchors.append(anchor)\n",
    "#             except Exception as e:\n",
    "#                 print(f\"‚ö†Ô∏è Timeout/Error: {str(e)[:50]}\")\n",
    "#                 failed_anchors.append(future_to_anchor[future])\n",
    "    \n",
    "#     print(f\"\\n‚úÖ Success: {len(dataset)}/{len(anchors)} ({len(dataset)/len(anchors)*100:.1f}%)\")\n",
    "#     print(f\"‚ùå Failed: {len(failed_anchors)}\")\n",
    "    \n",
    "#     return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel generation helper (commented) ‚ö°\n",
    "\n",
    "A robust parallel generation implementation using `ThreadPoolExecutor` is included as a commented reference. It includes timeout handling and progress reporting. Enable and adjust `max_workers` to suit your hardware.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restart_vllm_server():\n",
    "    \"\"\"Restart vLLM server.\"\"\"\n",
    "    print(\"üîÑ Restarting server...\")\n",
    "    !pkill -f vllm.entrypoints.openai.api_server\n",
    "    time.sleep(5)\n",
    "    \n",
    "    subprocess.Popen([\n",
    "        \"python\", \"-m\", \"vllm.entrypoints.openai.api_server\",\n",
    "        \"--model\", \"Qwen/Qwen2.5-7B-Instruct\",\n",
    "        \"--host\", \"0.0.0.0\",\n",
    "        \"--port\", \"8000\",\n",
    "        \"--gpu-memory-utilization\", \"0.8\",\n",
    "        \"--max-model-len\", \"1024\",\n",
    "        \"--disable-log-requests\",\n",
    "        \"--enforce-eager\"  # Disable CUDA graph to prevent memory issues\n",
    "    ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    \n",
    "    for i in range(40):\n",
    "        try:\n",
    "            response = requests.get(\"http://localhost:8000/v1/models\", timeout=3)\n",
    "            if response.status_code == 200:\n",
    "                print(\"‚úÖ Ready!\")\n",
    "                return\n",
    "        except:\n",
    "            pass\n",
    "        time.sleep(2)\n",
    "\n",
    "# Start initial server\n",
    "# restart_vllm_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Server restart helper üîÅ\n",
    "\n",
    "`restart_vllm_server()` attempts to gracefully kill and restart the vLLM server and waits until the server is healthy. Useful for long runs where memory leaks or failures may require a restart.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3a0de064c74113984deb13127a4c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Triplets:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Restarting server...\n",
      "‚úÖ Ready!\n",
      "üîÑ Restarting server...\n",
      "‚úÖ Ready!\n",
      "üîÑ Restarting server...\n",
      "‚úÖ Ready!\n",
      "üîÑ Restarting server...\n",
      "‚úÖ Ready!\n",
      "üîÑ Restarting server...\n",
      "‚úÖ Ready!\n",
      "üîÑ Restarting server...\n",
      "‚úÖ Ready!\n",
      "üîÑ Restarting server...\n",
      "‚úÖ Ready!\n",
      "üîÑ Restarting server...\n",
      "‚úÖ Ready!\n",
      "üîÑ Restarting server...\n",
      "‚úÖ Ready!\n",
      "üîÑ Restarting server...\n",
      "‚úÖ Ready!\n",
      "üîÑ Restarting server...\n",
      "‚úÖ Ready!\n",
      "üîÑ Restarting server...\n",
      "‚úÖ Ready!\n",
      "‚úÖ Done: 5000/5000\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "\n",
    "dataset = []\n",
    "restart_every = 400\n",
    "\n",
    "for idx, skill in enumerate(tqdm(skills_list, desc=\"Generating Triplets\")):\n",
    "    # Restart server every 400 requests\n",
    "    if idx > 0 and idx % restart_every == 0:\n",
    "        with open('checkpoint_title.json', 'w') as f:\n",
    "            json.dump({'dataset': dataset, 'idx': idx}, f)\n",
    "        restart_vllm_server()\n",
    "    \n",
    "    ans = generate_triplet(skill)\n",
    "      \n",
    "    if ans:\n",
    "        dataset.append(ans)\n",
    "    \n",
    "    # Save checkpoint every 50\n",
    "    if (idx + 1) % 50 == 0:\n",
    "        with open('checkpoint_title.json', 'w') as f:\n",
    "            json.dump({'dataset': dataset, 'idx': idx + 1}, f)\n",
    "\n",
    "print(f\"‚úÖ Done: {len(dataset)}/{len(skills_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main generation loop with checkpointing üíæ\n",
    "\n",
    "Iterates over `skills_list`, generates triplets, and periodically saves to `checkpoint_title.json`. Restarts the server every `restart_every` requests to mitigate memory issues. Adjust `restart_every` and checkpoint frequency as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "# dataset = []\n",
    "\n",
    "# for i in tqdm(skills_list,  desc=\"Generating Triplets\"):\n",
    "#     ans = generate_triplet(i)\n",
    "    \n",
    "#     if not ans:\n",
    "#         continue\n",
    "    \n",
    "#     dataset.append(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential generation (simple) üß≠\n",
    "\n",
    "A simplified, sequential loop that iterates `skills_list` and appends valid triplets to `dataset`. This is simple and robust but slower than parallel approaches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run generation\n",
    "# # Run with lower workers\n",
    "# generate_dataset_parallel(\n",
    "#     anchors=skills_list,\n",
    "#     max_workers=4,  # Try 8, then increase to 16 if stable\n",
    "#     timeout=60\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run parallel generation (commented) üõ†Ô∏è\n",
    "\n",
    "Example usage of the `generate_dataset_parallel` helper (commented out). Adjust `max_workers` and `timeout` before enabling for your system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results to CSV üì§\n",
    "\n",
    "After generation, convert `dataset` to a `pandas.DataFrame`, inspect, and save it to `title.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset) , len(failed_anchors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect dataset sizes and failures üìà\n",
    "\n",
    "Check the lengths of `dataset` and `failed_anchors` before converting to a DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_df = pd.DataFrame(dataset)\n",
    "\n",
    "skills_df.head()\n",
    "\n",
    "skills_df.to_csv(\"title.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to DataFrame and save to CSV üíæ\n",
    "\n",
    "Create a `pandas.DataFrame` named `skills_df` from `dataset`, preview it, and save to `title.csv` for downstream use.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
